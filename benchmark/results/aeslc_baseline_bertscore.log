Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
================================================================================
使用多种指标评估摘要质量
================================================================================

支持的指标:
  ROUGE: ✓
  BLEU: ✓
  BERTScore: ✓
================================================================================

正在计算BERTScore（95个样本）...
  注意：首次运行需要下载BERT模型（roberta-large，约1.3GB）
  如果网络连接有问题，可以：
  1. 设置环境变量: export HF_ENDPOINT=https://hf-mirror.com
  2. 或使用 --skip-bertscore 跳过BERTScore评估
  3. 下载可能需要10-20分钟，请耐心等待...
  使用HuggingFace镜像: https://hf-mirror.com
  正在计算BERTScore...
calculating scores...
computing bert embedding.
  0%|          | 0/6 [00:00<?, ?it/s] 17%|█▋        | 1/6 [00:07<00:35,  7.13s/it] 33%|███▎      | 2/6 [00:09<00:16,  4.14s/it] 50%|█████     | 3/6 [00:10<00:08,  2.95s/it] 67%|██████▋   | 4/6 [00:12<00:04,  2.30s/it] 83%|████████▎ | 5/6 [00:13<00:02,  2.02s/it]100%|██████████| 6/6 [00:14<00:00,  1.66s/it]100%|██████████| 6/6 [00:14<00:00,  2.42s/it]
computing greedy matching.
  0%|          | 0/3 [00:00<?, ?it/s]100%|██████████| 3/3 [00:00<00:00, 75.98it/s]
done in 14.56 seconds, 6.52 sentences/sec

总样本数: 95

平均分数:
  ROUGE1: 0.2008
  ROUGE2: 0.0282
  ROUGEL: 0.1286
  BLEU: 0.0109
  BERTSCORE: 0.8242

前10个详细结果:

[1] Summarize the following email: Huntley/question
...
    ROUGE-1: 0.1368
    ROUGE-2: 0.0000
    ROUGE-L: 0.1026
    BLEU: 0.0038
    BERTScore: 0.8281

[2] Summarize the following email: Expense Reports Awa...
    ROUGE-1: 0.1522
    ROUGE-2: 0.0222
    ROUGE-L: 0.1087
    BLEU: 0.0091
    BERTScore: 0.8073

[3] Summarize the following email: Re-start/Integratio...
    ROUGE-1: 0.2381
    ROUGE-2: 0.0645
    ROUGE-L: 0.1746
    BLEU: 0.0061
    BERTScore: 0.8281

[4] Summarize the following email: RM Simulation Story...
    ROUGE-1: 0.1600
    ROUGE-2: 0.0135
    ROUGE-L: 0.1200
    BLEU: 0.0072
    BERTScore: 0.8172

[5] Summarize the following email: Answer
...
    ROUGE-1: 0.2222
    ROUGE-2: 0.0132
    ROUGE-L: 0.1438
    BLEU: 0.0072
    BERTScore: 0.8145

[6] Summarize the following email: BCP Seat Assignment...
    ROUGE-1: 0.2703
    ROUGE-2: 0.0411
    ROUGE-L: 0.1486
    BLEU: 0.0083
    BERTScore: 0.8236

[7] Summarize the following email: Farewell Drinks
...
    ROUGE-1: 0.2105
    ROUGE-2: 0.0000
    ROUGE-L: 0.1263
    BLEU: 0.0084
    BERTScore: 0.8045

[8] Summarize the following email: Slide for John Sher...
    ROUGE-1: 0.1500
    ROUGE-2: 0.0256
    ROUGE-L: 0.1000
    BLEU: 0.0111
    BERTScore: 0.8236

[9] Summarize the following email: URGENT - ENA Associ...
    ROUGE-1: 0.2240
    ROUGE-2: 0.0163
    ROUGE-L: 0.1440
    BLEU: 0.0071
    BERTScore: 0.8294

[10] Summarize the following email: Increased Security ...
    ROUGE-1: 0.2267
    ROUGE-2: 0.0405
    ROUGE-L: 0.1333
    BLEU: 0.0094
    BERTScore: 0.8370

✓ 评估结果已保存到: ./benchmark/results/aeslc_baseline_100_evaluation_with_bertscore.json

================================================================================
指标说明：
  ROUGE: 基于n-gram重叠的摘要评估指标
  BLEU: 基于n-gram精确匹配的翻译/摘要评估指标
  BERTScore: 基于BERT语义相似度的评估指标
================================================================================
